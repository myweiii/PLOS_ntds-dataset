{
    "Introduction": "Since the year 2006, more than 7 billion treatments against Neglected Tropical Diseases (NTDs) have been delivered to people in need. More than 850 million people were treated in 2014 alone for lymphatic filariasis, schistosomiasis, soil-transmitted helminthiasis, onchocerciasis, and trachoma. Up to 1.4 billion people are targeted for coverage, requiring an investment of an estimated US$ 2.8 billion in the period 2015–2020.[1]\nThe six abovementioned NTDs are caused by different pathogens (including bacteria and helminths). However, only four drugs (albendazole, azithromycin, ivermectin or diethylcarbamazine and praziquantel) are needed to treat them and the strategy for delivering those medicines to reduce morbidity and prevent transmission is similar.[1] Mass treatment is known formally as Preventive Chemotherapy (PC) or Mass Drug Administration (MDA) in the case of the five abovementioned NTDs, and Total Community Treatment (TCT) in the case of yaws. Mass treatment involves the single-dose administration of (largely donated) medicines to entire populations at risk, without the need for diagnosis.\nIn advocating for mass treatment against the five PC diseases, the NTD community has typically cited values of US$0.10 to US$0.50 as the delivery cost per person per year. [1] These values exclude the cost of donated medicines. Whilst useful for advocacy, the focus on single numbers risks misrepresenting the complexity of delivering “free” medicines to about a billion people across the world.\nIn this study we conducted a literature review of existing studies and extracted and standardized estimates of the unit cost of delivering mass treatment (excluding the cost of the individual medicines themselves). We considered the six non-zoonotic NTDs for which mass treatment is recommended by the World Health Organization (WHO). Mass treatment is also recommended for foodborne trematodiases, however, scale up for these diseases is more recent with no current data on the cost of delivery.\nWe developed a regression model of unit costs to better understand the drivers of variation between the studies. The aim of the study was to use this model to “predict” what unit cost one might expect in different settings, along the lines of what has been done by WHO-CHOICE for estimating unit costs of general health services [2]. We called these predictions benchmarks. Benchmarks are setting-specific unit costs against which programme budgets and expenditures might be compared or benchmarked. The regression results were then used to create a web-based software application for planners, funders and researchers. The benchmarks might also inform the design of payment-by-results type financing mechanisms whereby funders agree to pay for outputs (e.g. the number of people treated) rather than inputs (e.g. personnel and equipment).",
    "Methods": "This study was undertaken in four steps: 1. Literature search and review; 2. Data extraction; 3. Meta-regression; 4. Benchmarking.\n\nLiterature Search and Review\nIn June 2015, we conducted a search of the available literature on the cost of PC or MDA for the five PC diseases and TCT for yaws. The search was conducted in PubMed, in English; the terms are provided in Supplemental Information (S1 Table). In order to maintain comparability in inputs, the search was limited to papers published since 1990. The initial literature search identified 182 studies.\nTitles and abstracts were assessed for inclusion. Criteria for inclusion were that: 1) that the population targeted be either all children or all adults (not, for example, just pregnant women); 2) the intervention be mass treatment, rather than individual (diagnosis and) treatment; 3) that the reported outcome (cost) be based at least in part on primary data (some estimation was allowed) and that sufficient detail be provided to ascertain whether these costs were financial or economic and what portion of the costs could be attributed to medicines.\nOn this basis, 136 studies were excluded. We reviewed the references of the remaining 47 studies and identified another 7 studies. A list of 54 references was shared with disease-specific focal points within WHO and one further study was proposed from the grey literature.[3] Primary data collected by one of the authors (FMF) was also considered for inclusion; these data are publicly available, as described under Data Extraction. A total of 56 full texts were assessed for inclusion in the meta-regression.\nUpon reviewing the full texts, we excluded a total of 22 studies, listed in Supplemental Information (S2 Table). Of those, 19 nineteen studies were based on the same cost data as an earlier study or another study reporting more detail. One study did not report the number of people treated. One study provided regional costs with no breakdown by country and one study provided costs for chemotherapy of detected cases only, not mass treatment.\nThis resulted in a final set of 34 studies being selected for inclusion in the meta-regression. These are listed in Supplemental Information (S2 Table). In December 2015, searches undertaken in English, French and Spanish using Google Scholar produced no additional studies.\n\n\nData Extraction\nUnit costs were defined as the cost per person per round, not per disease. We extracted unit costs or divided total costs by the number of people treated in a given year (across all rounds). We removed the medicines component (whether purchased or donated) and converted to base year prices (2015 US$) using the GDP deflator.[4] Definitions of what constituted financial or economic costs varied across the studies. We applied a standard classification according to Table 1. One of the notable differences between financial and economic costs relates to the inclusion of Ministry of Health buildings and staff time. While many studies mentioned patient time and the use of local (village or school) volunteers, few reported their (economic) costs and they were therefore excluded from the analysis. We nonetheless recorded the use of volunteers as a dummy variable for use in the meta-regression.\nWe extracted the number of people treated, the percentage of the target population that was treated, and other variables described in detail under Meta-regression. The coverage percentage was not always reported, nor the target population. For school-based programmes, we took the primary school net enrolment rate as a proxy for coverage. In the other cases, we estimated coverage using national data as reported to WHO.[5]\nFor study sites at the subnational level, we identified the geographical coordinates (administrative centres in the case of regions or districts) and nearest major cities (>100 000 inhabitants) and calculated the distance between them by road (in kilometres) using Google maps. We also recorded the travel time needed (in minutes by car), though this variable was later discarded as it performed no better than distance in predicting unit costs. In the absence of roads (e.g. in the islands of Papua New Guinea and Vanuatu) we used the flying distance to the nearest city.\nData were collated in a spreadsheet using Microsoft Excel. Data were then imported into R for data analysis and visualization.[6] All data are publicly available at https://healthy.shinyapps.io/benchmark/, through the web-based application software described below.\n\n\nMeta-regression\nWe employed meta-regression to examine whether differences in the average cost per person reported by included studies could be explained by moderator variables related to study methodologies or to the settings in which they were conducted.\nRegression analysis was performed with the plm package for panel data.\nWe used the study reference as the cross-sectional unit, which allows us to account for the possible clustering of effects due to methodological differences between studies. We used the year, site and comparator as the longitudinal unit. By comparator we refer to the fact that in any given year and site, a study may report and compare multiple costs: economic versus financial costs, integrated versus standalone costs, school-age children versus total population, or one round versus two rounds of delivery.\nModels were fit with both random and fixed (within) effects. However, for the purposes of benchmarking (outside of the sample), it would be problematic to select an appropriate fixed effect. We therefore focus in what follows on the random effects model. The results of the fixed effects model are provided in the Supplemental Information (S4 Table).\nModel 1 is a random effects model on the full set of observations;\n(1)\nModel 2 is a random effects model on the subset of observations that are subnational (regional or district) sites, which allows for the inclusion of the distance variable dis;\n(2)\nwhere\nucb is the unit cost (per person treated per round) in 2015 US$, excluding medicines and volunteer time; we consider with and without Purchasing Power Parity (PPP) conversion;\ni = 1,…,I studies;\nt = 1,…,T year-site-comparators;\nα is an invariant intercept;\neco is a dummy indicating whether the unit cost is economic (1) or financial (0);\nvol is the volunteer dummy for use of local volunteers, the cost of which is not included in ucb;\nint is an variable with the number of diseases for which treatment is delivered within a given round;\nrds is the average number of rounds per year;\nyrs is the number of years during which the programme has been implemented;\ncov is the percent coverage, or the number of people treated divided by the number of people targeted;\nsch is a dummy indicating school-based treatment of school children only;\npop is the number of people treated per round;\nden is the population density, defined as the total population divided by the land area, or people per km2;\nnat is a dummy variable indicating a national programme rather than a subnational site;\ngdp is Gross Domestic Product (GDP) per capita in 2015 US$; with and without PPP conversion;[7]\ndis is the distance in km from the study site to the nearest city of >100 000 inhabitants;\nuit is the between-study error; and\nεit is the within-study error.\nWe consider also the possibility of study- and country-specific dummy variables, as well as interactions between variables, as described in the Results.\n\n\nBenchmarking\nWe used the resulting regression model coefficients to estimate or predict unit cost benchmarks across a variety of settings.\nFor the tables of this paper, we generated country-specific benchmarks for both economic and financial unit costs. We set population treated (pop) to 10 thousand, 100 thousand and 1 million people respectively; the school-based (sch) dummy to 0; the national programme (nat) dummy to 1; the integrated delivery (int), years (yrs) and rounds (rds) variables to 1; the coverage (cov) and population density (den) variables to the sample medians (85% and 134 respectively). We set GDP per capita in 2015 US$ (gdp) to country-specific values, but constrained it to the maximum and minimum of the sample (2015 US$ 466 and 3737 respectively) to avoid extrapolating too far outside of the available data. We set the local volunteer (vol) dummy to 1 for financial benchmarks (resulting in lower cost) and to 0 for economic benchmarks (resulting in higher cost). To be clear, all unit cost benchmarks reported in this study exclude the cost of volunteer time. However, the economic unit cost benchmarks assume that volunteers are not used (i.e., that all labour inputs are paid).\nA web-based software application was developed using shiny (RStudio) to calculate setting-specific unit costs against which programme budgets and expenditures or results-based pay-outs can be benchmarked. In the software application, all of the above parameters can be chosen by the user.\nThe logarithmic transformation of the unit cost benchmark (ucb) was obtained with the vector of coefficients (B) and the matrix of new values for the explanatory variables (X) and\n\nThe standard error of the (log) estimate was calculated using\n\nwhere V is the variance-covariance matrix.\nWith the mean and standard error, we randomly drew from a normal distribution and re-transformed (exponentiated) 10 000 values and extracted the mean, 2.5th and 97.5th centile values for the best estimates and 95% Confidence Intervals (CIs). A 95% CI means that if the data are resampled, best estimates are expected to fall within this interval in 95% of the samples.\nIn the software application, we also provide prediction intervals (PIs). The standard error of the (log) prediction becomes\n\nwhere SSE is the sum of squared errors (residuals).\nA 95% PI means that if a single observation is resampled, the unit cost is expected to fall within this interval in 95% of the samples.",
    "Results": "Availability of Studies\nThe 34 studies included in the meta-regression cover 21 countries and 91 sites over 19 years for a total of 212 different observations of unit cost. The countries and sites from which the studies were taken are depicted, by disease, in Fig 1. A disproportionate number of observations are from Uganda (96).\nMost recent year refers to the most recent year of study, not the most recent year of publication.\nThere are 150 observations of financial cost from 29 studies and 130 observations of economic cost from 17 studies, with 12 studies reporting both (Table 2). Financial unit costs (excluding medicines) range from US$ 0.01 per treatment to US$ 8.50, with a median value of $0.20. Economic unit costs (excluding medicines and volunteer time) ranged from $0.02 to $2.90, with a median value of $0.40.\nMost studies are from low-income settings with 90% of observations from studies reporting the use of volunteers and 20% are from studies of school-based programmes. The average (median) observation is 116 816 people treated for 2 diseases over one round in the 3rd year of programme implementation. Median coverage was 85% overall, which was the same for the school-based programmes subset. Median population density was 134 people per km2; among the subset of subnational sites, the average population density was slightly higher (142 people per km2). Subnational sites were located an average (median) of 102 km from the nearest city of >100 000 inhabitants.\nFig 2 plots financial unit costs against populations treated, with each colour representing a different study. The lines show the log-log within-study relationship between unit costs and population treated. Similarly, Fig 3 shows the log-log within-study relationship between economic unit costs and population treated.\nDots represent individual study results, and lines represent the least squares line of best fit for studies with more than two results. The horizontal line at US$ 0.50 marks the oft-cited unit cost typically used in advocacy.\nDots represent individual study results, and lines represent the least squares line of best fit for studies with more than two results. The horizontal line at US$ 0.50 marks the oft-cited unit cost typically used in advocacy.\nThere are a number of clear outliers. Three studies stand out for their low estimates of cost, describing fewer cost categories than the others.[8][9][10] To the random effects regression model, we add dummy variables for these three studies. One study stands out for its high estimate of cost. In Tafea province (Vanuatu), the financial cost of TCT (for yaws) of 41 509 people distributed over five remote islands with very weak health and road infrastructure was about than 2015 US$ 8.47 per person.[11] To both the random and fixed effects regression models, therefore, we added a dummy variable for Vanuatu, a small island developing state (SIDS).\n\n\nPredictors of Unit Cost\nRegression model results for unit costs in 2015 US$ are presented in Table 3.\nThere is a significant and strongly negative association between unit costs and the number of people treated, confirming the expectation of important economies of scale. Similarly, an increase in the number of rounds per year is also associated with a significantly lower unit cost per person treated per round, suggesting that fixed (annual) costs can be shared across rounds too. Use of local (village or school) volunteers is associated with significantly lower unit costs, both financial and economic (including the cost of Ministry of Health staff time and assets but excluding the economic cost of volunteer time).\nPopulation density (meant to capture logistical ease of access) is negatively associated with unit costs among national programmes, but positively associated with unit costs among subnational programmes. Among these subnational sites, distance from the nearest city (meant to capture logistical difficulty) does not turn out to be associated with unit costs.\nIntegrated delivery of medicines is not associated with higher financial unit costs, but is associated with higher economic unit costs, suggesting that there may be some coordination costs related to integration.\nOverall, unit costs are higher in national programmes, implying some diseconomies of scale as geographic coverage moves from subnational sites to national programmes covering more diverse settings. However, among subnational sites, the association between unit costs and programme coverage is negative, especially in the case of school-based programmes. School-based programmes are associated with higher unit costs after controlling for coverage and the use of local volunteers; all school-based programmes benefited from high coverage (enrolment) and use of volunteers.\nGDP per capita is positively associated with unit cost, capturing (at least in part) the quality and complexity of inputs. The number of years or programme implementation (meant to capture any learning-by-doing effects) is not significantly associated with unit cost, but the (negative) sign of the coefficient is as expected. Unit costs are very much higher in Vanuatu, possibly reflecting the higher cost of implementation in a SIDS, and very much lower in the three studies which we deemed to be incomplete in terms of cost categories.\nSince the distance variable (subnational data) is not statistically significant, we proceed in what follows with random effects Model 1 (based on the full set of data). The R2 statistic suggests that it explains about two thirds of the variation in unit costs reported in the literature. Transforming unit costs into PPP dollars does not much improve the explanatory power of the model. We therefore remained with the arguably more easily and widely understood estimates based on unit costs in US$. Results in PPP dollars are nonetheless presented with the fixed effects model results in the Supplemental Information (S4 Table).\n\n\nUnit Cost Benchmarks\nBenchmarks for the financial unit cost in US$ are depicted in Fig 4 for all low and middle income countries, at three different scales of implementation. For programmes treating 100 000 people or more, the financial unit cost benchmark is less than US$ 0.50 for the vast majority of countries. However, the benchmark can exceed US$ 2.00 for programmes operating at a scale of about 10 000 people.\nThe legend excludes Vanuatu. See S5 Table in the Supplemental Information for results for Vanuatu.\nSimilarly, benchmarks for the economic unit cost in US$ are depicted in Fig 5. For programmes treating 100 000 people or more, the economic unit cost benchmark is less than US$ 1.00 for the vast majority of countries. However, the benchmark can exceed US$ 10.00 for programmes operating at a scale of about 10 000 people.\nThe legend excludes Vanuatu. See S5 Table in the Supplemental Information for results for Vanuatu.\nBenchmarks for both financial and economic unit costs are presented in data tables with 95% confidence intervals in the Supplemental Information (S5 Table). These regression results were used to create a web-based software application available at https://healthy.shinyapps.io/benchmark/. Users can enter setting-specific parameter values to arrive at a benchmark unit cost for their setting. These benchmarks can be compared by researchers to individual unit cost estimates extracted from the studies. A guide to using the application can be found in Supplemental Information available within the application at the abovementioned link.\nAll unit cost benchmarks reported by the web-based application exclude the opportunity cost of local volunteer time. However, one can choose to assume that volunteers are not used for the mass treatment campaigns, in which case the unit cost benchmarks are estimated as though all labour inputs are paid at their respective wages. This is true whether one chooses the random effects or the fixed effects model.",
    "Discussion": "This study provides the most up-to-date review of the literature on the cost of mass treatment for the control and elimination of six selected NTDs for which mass treatment is recommended by WHO. For the first time, the evidence has been standardized and synthesized in a meta-regression of the cost per person treated per round, controlling for differences between settings. We find that unit costs are very sensitive to economies of scale, and the decision on whether or not to use local volunteers. Financial unit costs are expected to be less than 2015 US$ 0.50 in most countries with programmes that treat 100 000 people or more. However, for smaller programmes, including those in the “last mile”, or those that cannot rely on volunteers, financial unit costs may be considerably higher.\nSome of the regression results are surprising. Among subnational project sites, we do not find the expected significant positive association between unit cost and coverage nor between unit costs and population density or distance from the nearest city. These surprising results warrant further investigation; there may be better measures of logistical ease/difficulty of access.\nThis study then uses the meta-regression results to predict unit costs across a large number of different possible settings. One of the advantages of this approach over taking a simple arithmetic average across (subsets of) the available data is that it also gives robust confidence intervals. The confidence intervals can be used in economic evaluations, including cost-effectiveness analyses looking to generalize results across settings, but are not meant to be used as substitutes for detailed planning and budgeting. However, confidence intervals can be used to assess value for money in programme plans, budgets and accounts, or help set a reasonable pay-out for results-based financing mechanisms.\nThe approach can be used for other outreach interventions, beyond health care facilities, that may gain in importance in the context of universal health coverage. Indeed, our benchmarks may be relevant for intermittent preventive treatment (IPT) against malaria. IPT involves a full course of an anti-malarial treatment in areas of seasonal transmission, regardless of individual infection. In Ghana, the economic cost was at least US$ 2.35 (2008) per month of intervention for a group of 613 children that received IPT.[12]\nIn future, unit costs of mass treatment against NTDs could be benchmarked against the unit cost of other mass interventions. A review of the cost of vitamin A supplementation suggests that unit costs can vary by a factor of more than 1000 and are several-fold higher than has traditionally been maintained.[13] Our benchmarks are unlikely to be of relevance to mass immunization requiring a costly cold chain. However, they could give an indication of cost savings associated with the integration of mass treatment against NTDs within existing immunization campaigns.[14]\nThere are a few caveats. For one, confidence and prediction intervals are wide and even so do not fully reflect true uncertainty. While there are a good number of studies available, they do not cover as many countries as there are studies. Most report only financial costs, excluding the cost of Ministry of Health resources (buildings and staff), for example, and therefore fail to estimate the full costs to the health system. Many appear to be from peri-urban areas rather than from the rural areas in which most of the population requiring treatment is found or indeed from the remotest areas where one would expect unit costs to be highest.\nAnother limitation is that while most programmes used volunteers, few studies considered the economic cost of their time. We controlled for the use of volunteers in the regression model and estimate that, all other things being equal, the financial cost more than doubles in going from volunteers to paid health workers. Unfortunately, the use of unpaid volunteers may not be scalable: “fully-scaled NTD control programmes covering over a billion people cannot expect to recruit and retain sufficient numbers of volunteers if other major disease programmes are offering incentives.”[1]\nFurthermore, while the focus continues to shift from control to elimination, most of the available costing studies are of control programmes. Of the 34 studies identified in our review, only 8 referred explicitly to eradication (yaws) or elimination (LF, onchocerciasis) as a programme objective.[11][15][16][17][18][19][20][21] Only one of those directly compared the costs of control and elimination strategies (for onchocerciasis), involving annual and biannual (twice yearly) mass treatment respectively; the difference is determined by the number of rounds rather than by so-called “last mile” costs.[21]\nNo study has been conducted in a country where eradication or elimination has actually been achieved. Egypt stopped PC and started post-PC surveillance for LF in 2014, but the available costs are from 2000–2001. Challenges to elimination posed by the parasite Loa loa, that can cause fatal side-effects upon anthelmintic treatment, have not been factored into any of the available costing studies of LF, and into only one country from one study of onchocerciasis.[3]\nFinally, most of the available costing studies consider the early years of programme implementation. Some considered the cost of planning and mapping in these early years, but few considered longer-term monitoring and evaluation. A micro-costing study based on other sources (and therefore excluded from the meta-regression) estimates that the financial unit cost per treatment would increase two times towards the later phases of elimination of onchocerciasis in Africa.[22] This increase is driven by the reduction in the number of people in need of treatment and steady or increasing costs for surveillance.\nKlepac et al (2015) provide a good summary of why the distinction between the “middle game” and the “endgame” matters.[23] First, the endgame is associated with higher unit costs; the last foci of infection or pockets of susceptibility will be those that are hardest to reach, either geographically or socially (e.g. treatment refusers). Second, the endgame may present fewer opportunities for cost-sharing across interventions; while elimination can and should continue to be delivered by strong health systems, frequency and timing become less flexible in the endgame.\nThe duration and total cost of the endgame is likely to be a function of: “the underlying biology of the pathogen, the demography of the host(s), the connectedness of affected populations, the speed of roll out of control measures, their efficacy and the capacity for sustained effort, likely to be itself shaped by political agendas and financing.”[24] A prolonged and expensive endgame can lead to funder fatigue and motivate a (premature) switch in strategy from, for example, mass treatment to targeted treatment in remaining foci of infection or high-risk locations or populations.\nWhile our review of the literature, published and grey, was thorough, more could be done to identify more studies, such as: looking at more databases and considering other languages spoken in a small number of endemic countries, namely Arabic, Chinese and Portuguese. In future, country and technical expert groups could be convened to reconsider the data and approach used, similar to benchmarking work undertaken for the Global Fund to Fight AIDS, Tuberculosis and Malaria.\nOther refinements to this study might include benchmarks for the cost of post-mass treatment mop-up, known more formally in the trachoma and yaws literature as “enhanced coverage” and “total targeted treatment”, respectively, in which communities are visited a second time to treat only those not treated on the first visit.[11][25] More evidence is needed on the cost of post-mass treatment surveillance, including Transmission Assessment Surveys, and certification of eradication or elimination. Indeed, we are not aware of any studies of the cost of eradication or elimination of diseases (including guinea-worm disease or poliomyelitis) that explicitly included the cost of the certification process.\nThis comprehensive analysis confirms that mass treatment offers a low cost public health intervention on the path towards universal health coverage. However, more costing studies focussed on elimination are needed. The novel web-based platform https://healthy.shinyapps.io/benchmark/ can be used to determine realistic unit cost benchmarks to assist monitoring value for money in NTD programme plans, budgets and accounts, or in setting a reasonable pay-out for results-based financing mechanisms by Ministries of Health and Finance in low- and middle-income countries."
}