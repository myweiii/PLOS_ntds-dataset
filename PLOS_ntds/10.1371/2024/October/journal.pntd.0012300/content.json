{
    "1. Introduction": "Q Fever (QF) and Rift Valley fever (RVF) are zoonotic diseases prevalent in several African countries [1]. Reported prevalence rates range from 7.8% to 39% for QF and 9.5% to 44.2% for RVF in livestock, and from 27% to 49.2% for QF and 13.2% to 28.4% for RVF in humans [1–4]. QF and RVF impact human health by causing a flu-like syndrome that can lead to a range of severe clinical manifestations. QF and RVF also result in significant production losses in animals due to abortions [5,6].\nHigh-quality samples and robust diagnostic tests are essential for obtaining accurate prevalence estimates. Epidemiological studies play a critical role in generating the necessary data, subsequently influencing government prioritization of health interventions [7,8]. This prioritization is fundamental to effective disease control.\nFor QF diagnostics, the indirect immunofluorescence assay (IFA) can differentiate between acute and chronic infections and is regarded as the gold standard test for humans [9,10]. However, commercial IFA kits are not available for veterinary use [11]. The enzyme-linked immunosorbent assay (ELISA) is the most widely used test and is recommended by the WOAH (World Organisation for Animal Health) for rapid routine screening and large-scale epidemiological studies in ruminant populations [7]. For RVF, the virus neutralization test (VNT) is the most specific serological diagnostic test [8]. However, it requires living cell cultures, titered virus stocks, and highly trained personnel, making it labour-intensive, costly, and time-consuming (minimum 48 hours) [12]. Additionally, working with viable viruses poses a biohazard risk, making VNT unsuitable for use in laboratories without appropriate biosecurity facilities and vaccinated personnel [6,8]. For both diseases, ELISAs offer a rapid, cost-effective, and practical alternative with less stringent biosafety requirements, making them suitable for routine use in low- and middle-income countries (LMIC) [7,8].\nThe use of ELISA in some studies and the gold standard test, which may differ between countries, in others can lead to discrepancies in estimated prevalence, making comparisons challenging; thus, harmonized monitoring and reporting schemes for QF and RVF have been proposed to enable consistent comparisons over time and across countries [13–15].\nSeveral studies have assessed the inter-test agreement of ELISA for QF and RVF compared to other diagnostic tests, reporting variable agreement ranging from poor to good for QF and from good to excellent for RVF [16–22]. Diagnostic test validation can be achieved through various methods, including assessing the agreement between different tests without assuming one as the gold standard [23]. Concordance, the proportion of test results in agreement over the number of all tests performed, is a straightforward measure but does not account for agreement beyond chance. Therefore, Cohen’s kappa statistic, which adjusts for random matches, is often used to measure the agreement between two test results [23]. Cohen’s kappa values range from zero (agreement is equal to that expected by chance) to one (complete agreement beyond chance), with benchmarks between agreement categories varying among authors [24–26]. Although Cohen’s kappa is a standard measure, it has limitations such as prevalence and bias effects. Prevalence effects arise when the proportion of positive results deviates significantly from 50% [27]. The effect of prevalence depends on the method of modeling agreement and can substantially reduce kappa values [27]. Bias effects occur when there is a disparity in the proportion of positive results between the two tests, which leads to reduced kappa values [27]. To address these effects, the prevalence- and bias-adjusted kappa (PABAK) can be calculated [28,29].\nThe reasons for disagreement between diagnostic tests have rarely been thoroughly investigated. Potential factors include poor sample quality, variability in tests used, and discrepancies arising from the same test being conducted in different laboratories [18,22,30]. Additionally, biological factors such as age, sex, other diseases, and species may influence the consistency of test results for the same sample. Previous studies have suggested associations between test performance and variables such as region, age, and livestock species [31–33]. However, these studies have not provided conclusive evidence or statistical significance.\nThe objective of this study was to assess the inter-laboratory agreement of standard diagnostic tests utilized by the participating laboratories, measured by the concordance, Cohen’s kappa, and PABAK. The comparison involved results obtained from commercial ELISA tests conducted in a laboratory in Chad and results obtained from ELISA and indirect IFA tests performed on livestock and human serum aliquots, respectively, in laboratories in Germany and Switzerland. Additionally, we evaluated the influence of demographic factors on the agreement between the two test results. The study enhances our understanding of the inter-laboratory agreement of diagnostic test results across laboratory conditions and, for humans, test types, which is crucial for accurately interpreting results from epidemiological seroprevalence studies.",
    "2. Material and Methods": "2.1. Ethics statement\nThe study was approved by the Ethics Committee of Northwest and Central Switzerland (EKNZ) (project id 2017–00884) and by the Comité National de Bioéthique du Tchad (CNB-Tchad) (project id 134/PR/MESRS/CNBT/2018). Formal written consent was obtained from study participants and animal owners after we presented our study to the community and before data collection occurred.\n\n\n2.2. Sample collection and laboratory analysis in Chad\nThe samples analysed in this study were collected between January and February 2018, as reported by Özcelik, R., et al [4]. In brief, a cross-sectional study in livestock (cattle, sheep, goats, horses, and donkeys) and human populations was conducted in the two rural health districts, Yao and Danamadji, in Chad. Multistage cluster sampling was used, with villages and nomadic camps serving as cluster units. The clusters were chosen based on human population size. The sample size was calculated using R software, assuming a 50% prevalence for Q fever, and RVF, with a 95% confidence interval. The sample size for two-stage cluster sampling was determined using a formula incorporating the sample size for simple random sampling, the intra-cluster correlation coefficient of 0.2, and the number of 20 individuals sampled per cluster [4]. In Danamadji and Yao, respectively, blood samples were collected from 571 and 389 humans and 560 and 483 livestock. No individuals showing clear signs of illness were sampled, and similarly, animals that were visibly ill and hence often isolated were also excluded from the sampling [4].\nThe samples were subsequently analysed at the Institut de Recherche en Élevage pour le Développement (IRED) in N’Djamena, Chad. Livestock and human samples were analysed using different indirect ELISAs: ID Screen Q Fever Indirect Multi-species ELISA from IDvet for livestock and the Panbio Coxiella burnetii IgG ELISA from Abbott for humans. For RVF, a competitive ELISA (ID Screen Rift Valley Fever Competition Multi-species from IDvet) was used for human and livestock samples. The diagnostic test procedure and thresholds were applied according to the manufacturer’s protocols without modification (S1 Table). Equivocal samples were retested once.\n\n\n2.3. Diagnostic testing in Switzerland and Germany\nFollowing the initial diagnostic analysis at IRED, 10% of the human and livestock samples from each region were randomly selected and sent as serum aliquots to laboratories in Switzerland and Germany in 2021 for repeated diagnostic analysis for QF and RVF, respectively. The decision to use a 10% subsample of the original sample size was based on the resources available. In Switzerland, two indirect ELISAs (IDEXX Q Fever IgG Antibody and ID Screen Q Fever Indirect Multispecies from IDvet) were used at the Center for Zoonoses, Animal Bacterial Diseases, and Antimicrobial Resistance (ZOBA) for QF diagnostics in livestock samples (ruminants and equids, respectively). At the Institute for Infectious Diseases (IFIK) of the University of Bern, an indirect IFA (Q Fever IFA IgG assay from Focus Diagnostics, US) was used for QF diagnostics in human samples. For RVF, livestock samples were analysed using a competitive ELISA (ID Screen Rift Valley Fever Competition Multi-species ELISA from IDvet) at the Friedrich-Loeffler-Institute (FLI), and human samples were analysed using an indirect IFA (Anti-Rift-Tal-Fieber-Viren-IIFT [IgG] from EUROIMMUN) at the Robert Koch Institute (RKI). The diagnostic test procedure and thresholds were applied according to the manufacturer’s protocols without modification (S1 Table). Equivocal samples were not retested.\n\n\n2.4. Sample processing\nOf the 206 serum aliquots from 103 livestock samples and 192 serum aliquots from 96 human samples sent to laboratories in Switzerland and Germany, 15 livestock aliquots and 30 human aliquots were excluded from further analysis (Table 1). Reasons for exclusion included unsuccessful matching of test identities due to labelling errors, missing serum upon arrival, and equivocal results (Table 1). As a result, one livestock sample and five human samples were fully excluded from the study sample. Ultimately, 91 human and 102 livestock samples were tested using one or both assays and were included in the agreement testing (Table 1, Fig 1).\nThe specific tests used in each laboratory are noted, along with the antibodies detected (IgG = Immunoglobulin G). The number of samples processed at each stage is provided. Different colors in the diagnostic tests indicate that assays from different manufacturers were employed. Of the original 103 livestock and 96 human samples sent to Germany and Switzerland, 102 livestock and 91 human samples underwent either both QF and RVF diagnostics or one of the tests. One livestock sample and five human samples were unavailable for any diagnostic procedure and were fully excluded from further analysis. Abbreviations: ZOBA: Center for Zoonoses, Animal Bacterial Diseases, and Antimicrobial Resistance; IFIK: Institute for Infectious Diseases; FLI: Friedrich-Loeffler-Institute; RKI: Robert Koch Institute; ELISA: Enzyme-linked Immunosorbent assay; IFA: Immunofluorescence assay. Figure created with BioRender.com.\n\n\n2.5. Statistical analysis\nThe inter-laboratory agreement of the test results from Chad and Switzerland or Germany was evaluated using concordance, Cohen’s Kappa, and PABAK for each of the four datasets: QF results in human samples, QF results in livestock samples, RVF results in human samples, and RVF results in livestock samples. Cohen’s kappa and PABAK values were interpreted according to the standard scale: ’fair’ agreement (kappa = 0.21–0.40), ’moderate’ agreement (kappa = 0.41–0.60), ’substantial’ agreement (kappa = 0.61–0.80), and ’almost perfect’ agreement (kappa > 0.80) [26].\nIn addition, we investigated factors associated with test agreement by assigning to each sample a value of 0 if there was disagreement between the two test results (i.e., negative in Chad and positive in Switzerland/Germany, or the opposite) and 1 if the test results were consistent (i.e., both positive or both negative). This binary outcome was used as the dependent variable in logistic regression models to identify the statistical association between test agreement and demographic factors, including the district (Yao versus Danamadji) and setting (village versus camp) where the sample was collected, and sex, age, and livestock species (cattle, small ruminants, and equids) of the sampled individual. The variable age was analysed in two ways, as a continuous and as a categorical variable. For the continuous variable, a unit of 1 year was used for livestock and of 10 years for humans. For the categorical variable, samples were stratified as < 2 years (age group 1), 2–3 years (age group 2), 4 years and older (age group 3) for livestock, and < 30 years (age group 1), 30–39 years (age group 2), 40–60 years (age group 3), 61 years and older (age group 4) for humans.\nUnivariable logistic regressions were initially performed to assess individual predictors. In cases where the univariable model was infeasible due to perfect agreement in one group, Chi-square tests were applied. Odds ratios (OR) and their corresponding 95% confidence intervals were calculated for these analyses. To consider potential interdependencies between the variables, we applied multivariable logistic regressions to estimate adjusted coefficients and OR. We included all variables and selected age as categorical variable.\nStatistical calculations, modeling, and data visualization were conducted in R (version 4.2.2). The package “irr” was used to calculate the concordance and Cohen’s kappa. The package “vcd” was used to obtain confidence intervals of Cohen’s kappa, computed using the standard method based on normal approximation [34]. The epi.kappa() function from the “epiR” package was used to calculate PABAK and corresponding confidence intervals. The confidence intervals for the OR were calculated using the output values of the associated regression model, with the upper and lower CIs derived using the function exp(confint.default(model)).",
    "3. Results": "3.1. Sample population\nOf the 91 human and 102 livestock samples that were used to perform the inter-laboratory test agreement analysis, most (62% of human and 57% of livestock) samples were collected from Danamadji (S2 Table). Fifty-six percent of human samples and 58% of livestock samples were collected from camps. The sex distribution was uneven, with 70% of human sampled being male and 70% of livestock sampled being females. Among humans, age groups 1–3 were evenly represented (30%, 28%, 33%), while only 9% belonged to age group 4. In livestock, 50% of the samples were from age group 2, with 17% and 33% from age groups 1 and 3, respectively. Most livestock samples were from cattle (46%), followed by small ruminants (41%) and equids (13%) (S2 Table). The livestock sampled originated from 24 different herds (one herd per cluster).\n\n\n3.2. Diagnostic tests agreement\n3.2.1 Level of inter-laboratory test agreement.Concordance values ranged from 62.5% to 94% (Table 2). Cohen’s kappa values, which ranged from 0.31 to 0.59, indicated that livestock QF and RVF, and human RVF tests had ’moderate’ agreement, while human QF tests had ’fair’ agreement (Table 2). PABAK values showed that the livestock QF and RVF tests had ’almost perfect’ agreement, the human RVF test had ’substantial’ agreement, and the human QF tests had ’fair’ agreement (Table 2).\n\n3.2.2. Influence of factors on inter-laboratory test agreement.For QF in livestock, none of the investigated demographic factors significantly impacted the agreement between the two test results in both univariable and multivariable analyses (Tables S3 and 3). However, some notable trends (p < 0.15) emerged: small ruminants tended to show better agreement than cattle, and samples from Yao showed lower agreement compared to those from Danamadji (Table 3). For QF in humans, samples from villages had significantly higher agreement compared to those from camps, with odds of agreement being 13.4 times higher (Table 3). Additionally, older age groups had significantly lower agreement compared to the youngest age group (Table 3).\nGoodness of fit of the models are presented as pseudo-R-squared (R2). Bold p-values indicate significance based on a threshold of 0.05.\nFor RVF in humans and livestock, none of the demographic factors significantly influenced test agreement. However, some trends were observed for RVF test agreement in humans, with older age groups showing lower agreement compared to the youngest age group (Table 3).\nAcross diseases and populations, there was a consistent trend of lower agreement with increasing age, which was significant for human QF and almost reached significance for human RVF (Table 3 and Fig 2). For livestock RVF tests, the odds ratio for agreement was also lower in older age groups, although the p-value was 0.26 (Table 3).\nThe heights of the rectangles represent the proportion of individuals within each age group who exhibit a specific test agreement outcome (concordant or discrepant). Abbreviations: QF: Q fever; RVF: Rift Valley fever.",
    "4. Discussion": "Our study revealed varying levels of test agreement, ranging from fair to moderate (Cohen’s kappa) or almost perfect when considering PABAK. The good inter-laboratory agreement of livestock test results for RVF was in line with other studies on RVF test agreement, although it is important to note that literature on this subject is limited [20,21]. Similarly, the body of research on test agreement for livestock QF is also limited. The inter-laboratory agreement for livestock QF observed in our study was slightly lower than the values reported in previous studies that evaluated agreement between different ELISA tests or between ELISA and IFA [18,19]. However, those previously reported test comparisons were performed within the same laboratories and time frame, which may explain the observed differences in agreement. Notably, the livestock RVF agreement was assessed using the same ELISA from the same manufacturer in both Chad and Germany. In contrast, for livestock QF, only the equid samples were tested using the same ELISA in Switzerland as in Chad, whereas ruminant samples were analyzed with an ELISA from a different manufacturer. The latter ELISA was adapted for automation in ruminants and was therefore the standard assay used by the participating laboratory for this species. This discrepancy may have contributed to the better inter-laboratory agreement observed for livestock RVF compared to livestock QF.\nWe observed a notably lower agreement for human tests compared to livestock tests for both diseases, which may be attributed to using two different diagnostic methods for human samples, ELISA in Chad and indirect IFA in Switzerland or Germany. Previous studies have shown varying sensitivities and specificities of the commercial diagnostic test for QF used in this study (Panbio from Abbott), ranging from 71% to 100% [10,35–37]. In these studies, indirect IFA was used as a reference method to evaluate the ELISA, revealing varying agreement between the results of the two tests. The variability in sensitivity for the same test raises the question of whether it is due to the scope for interpretation in indirect IFA, which is considered a challenge, even though indirect IFA is regarded as the gold standard for human QF diagnostics [5,7]. A study that compared QF indirect IFA results from different reference centres in three countries (United Kingdom, France, and Australia) found a concordance between the indirect IFA results of only 35% [38]. Our results reflect this uncertainty and underline the complexity of QF diagnostics [5,7,39]. A previous study comparing IFA (the same test used in our study) and ELISA (from a different manufacturer than the one used in our study) found that IgG phase II antibody titers decline more slowly when measured by IFA, with significantly higher detection rates after one year [40]. These findings indicate that IFA may offer superior sensitivity and longer-lasting detection of IgG phase II antibodies compared to ELISA, which may account for the lower agreement observed in the human QF tests in our study. Similarly, for RVF, the lower inter-laboratory agreement for human tests compared to livestock tests may be attributed to the use of different testing methods in Chad (ELISA) and Germany (indirect IFA). The reported sensitivity and specificity values for the ELISA kit used in Chad are 98% and 100%, respectively [20]. While the IFA test used in Germany (EUROIMMUN RVF IFA IgG assay) is a certified assay, its performance has not been evaluated by external independent assessment [12]. The existing literature on RVF diagnostic tests, particularly IFA, is limited. Generally, IFA can achieve high specificity and sensitivity; however, these metrics are highly dependent on the operator’s skill in interpreting fluorescent signals under a microscope and the quality of the reagents used [41].\nAlthough quantitative information on the quality of the individual samples in our study are unavailable, laboratory staff in Switzerland and Germany reported concerns regarding haemolysis. Given that haemolysis is a well-documented cause of test result discrepancies in clinical laboratories [42,43], it may have contributed to the observed disagreement between test results in our study. Although serum was sent to the laboratories in Germany and Switzerland, haemolysis may have occurred before or during the process of separating serum from whole blood. Consequently, the serum could contain haemoglobin and other intracellular components from lysed red blood cells, potentially compromising the quality of the sample and interfering with laboratory tests [43]. There are many in vitro causes of haemolysis, mostly pre-analytical problems such as incorrect procedures and/or materials used in blood collection, while transport, processing, and storage account for only a minority of cases [44]. This limitation shows the importance of careful planning and execution of the pre-analytical phase, especially in prevalence studies where the outcome can be influenced by the quality of the sample material. Nevertheless, it is crucial to recognize the challenges associated with collecting samples under difficult field conditions, where access to centrifuges may be limited until several days after blood sampling. In addition, the samples in our study were stored for 2.5 years with repeated freeze-thaw cycles between the performance of the two tests for some of the samples, which probably affected sample quality. Several studies have assessed the effects of repeated freeze-thaw cycles on IgG stability, although not specifically on Anti-QF/RVF IgG, and found minimal impact [45,46]. However, the effects of prolonged storage have not been explored. Future research should investigate whether extended storage, such as the period between processing at the local laboratory and further analysis at secondary laboratories, could compromise sample quality, and consequently test results. We emphasize the importance of considering these challenges when discussing the outcomes of epidemiological prevalence studies or diagnostic test evaluation studies.\nOur results demonstrate a statistical relationship between test agreement and age of the sampled individuals, with higher agreement observed in younger individuals for both diseases and in humans and livestock. This finding aligns with a study by de Bronsvoort et al. (2019), which suggested that lower agreement in older individuals may be due to their higher likelihood of previous exposure to other pathogens over their lifetime [31]. This may result in cross-reactivity in serological tests, making serological differentiation between diseases more difficult [39]. Cross-reactions caused by antibodies induced by other pathogens, such as C. burnetii antigens, the agent causing QF, with antibodies produced against Bartonella spp., Legionella spp., and Chlamydiae spp. has been reported [47–49], or RVF virus antigens with antibodies produced against Rio Grande virus [50–52]. Furthermore, with increasing age, the likelihood of exposure to the causative agent of QF and RVF increases [53,54], as does the chance of having residual antibodies against these diseases in the blood [6,55–57]. In addition, in QF, antigen-lipopolysaccharide complexes remaining in the host after infection with C. burnetii can trigger humoral and cell-mediated immune responses, producing interfering antibodies [58,59]. Such antibody titres can potentially produce ambiguous results that are neither clearly positive nor negative, leading to misinterpretation and discordant test results. Additionally, immunosenescence–the gradual deterioration of the immune system associated with aging–may also play a role in the increased disagreement of diagnostic test results among older individuals. Immunosenescence is characterized by reduced immune function, altered antibody responses, and an increased tendency toward chronic inflammation, including the presence of proinflammatory \"age-associated B cells,\" which have been shown to produce autoantibodies [60–62]. These autoantibodies may interfere with antigens used in diagnostic tests; a hypothesis that warrants further investigation. Consequently, these findings underscore the need for further research to develop age-specific diagnostic protocols, such as adjusting cut-off values for interpreting results, and to improve test accuracy across diverse populations.\nThe district-level analysis showed a trend toward higher agreement for livestock QF tests in samples from Danamadji compared to Yao. This regional variation may be influenced by varying local environmental conditions, disease prevalence, or livestock management practices. However, we did not capture such information, so we were not able to identify a potential latent factor that can explain the difference in test agreement detected for the two regions. Continuing with the focus on sampling location, the sample collection setting (village versus camp) was identified as a significant factor in the multivariable model for human QF test agreement. One hypothesis for this finding is that villages generally have shorter distances from the sampling location to the laboratory, allowing for more appropriate storage conditions compared to remote camps. This shorter travel time likely preserves sample integrity, resulting in higher test agreement. The significant role of the setting variable suggests that environmental and logistical factors may be crucial for diagnostic test result interpretation, although we did not observe the influence of the setting for RVF in humans nor for livestock species. Future studies should investigate the impact of environmental and logistical factors on test results and gather detailed data on local conditions and practices that affect sample quality and test agreement.\nSmall ruminants exhibited a trend towards higher agreement in QF test results compared to cattle. In a different type of QF ELISA, Stellfeld et al. (2020) observed significant differences in the ranges of OD450 values obtained from sera of sheep, goats, and cattle [63]. Sheep exhibited a larger range of OD450 values, whereas cattle showed a smaller range [63]. Greater distribution between OD450 values allows for more precise grading of ELISA results, which may explain the better inter-test agreement for small ruminants compared to cattle. These differences in OD450 ranges are likely due to species-specific immune responses to C. burnetii, suggesting varying immune reactions among ruminant species [63].\nAlthough females showed lower inter-laboratory test agreement compared to males for both diseases and populations, the high p-values and wide confidence intervals of the ORs in our data did not indicate any significant influence of sex on the inter-laboratory test agreement.",
    "Conclusion": "Our study highlights the variability in inter-laboratory diagnostic test agreement for QF and RVF serology in humans and livestock based on samples collected in Chad. Despite differences in laboratories, personnel, and test types, test agreements ranged from fair to moderate (Cohen’s kappa) or almost perfect considering PABAK. Given the reliance on serological profiles for QF and RVF epidemiological studies, it is crucial to consider factors that may complicate accurate diagnosis. We identified that human QF test agreement was significantly higher in individuals living in villages and younger individuals, with the latter trend also observed in human RVF tests. Our findings emphasize the need to recognize that diagnostic tests may yield varying results, impacting the outcome and interpretation of disease prevalence studies. If resources permit, it is recommended to confirm positive results by retesting with the gold standard test.",
    "Declaration of generative AI and AI-assisted technologies in the writing process": "While preparing this work, the author used ChatGPT to correct the English of revised sentences (using the command: ‘correct the English’). After using this tool, the author reviewed and edited the content as needed and takes full responsibility for the content of the publication."
}